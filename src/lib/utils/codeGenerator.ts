import { BuildState } from '@/lib/stores/buildStore'

export interface GeneratedFile {
  path: string
  content: string
}

export interface ExportOptions {
  format: 'typescript' | 'python'
  includeDependencies: boolean
  includeReadme: boolean
}

export function generateCode(
  buildState: BuildState,
  options: ExportOptions
): GeneratedFile[] {
  const files: GeneratedFile[] = []
  const buildId = `build_${Date.now()}`
  const timestamp = new Date().toISOString()

  // Generate agent configuration
  const agentConfig = generateAgentConfig(buildState)

  if (options.format === 'typescript') {
    // Generate TypeScript agent file
    const agentCode = generateTypeScriptCode(buildState, buildId, timestamp, agentConfig)
    files.push({
      path: 'src/agent.ts',
      content: agentCode
    })

    // Generate API route
    const apiRoute = generateNextJSRoute()
    files.push({
      path: 'src/app/api/agent/route.ts',
      content: apiRoute
    })

    if (options.includeDependencies) {
      files.push({
        path: 'package.json',
        content: generatePackageJson(buildState)
      })
      files.push({
        path: '.env.example',
        content: generateEnvExample(buildState)
      })
      files.push({
        path: '.gitignore',
        content: generateGitignore()
      })
    }
  } else {
    // Generate Python agent file
    const agentCode = generatePythonCode(buildState, buildId, timestamp, agentConfig)
    files.push({
      path: 'agent.py',
      content: agentCode
    })

    if (options.includeDependencies) {
      files.push({
        path: 'requirements.txt',
        content: generateRequirementsTxt(buildState)
      })
      files.push({
        path: '.env.example',
        content: generateEnvExample(buildState)
      })
      files.push({
        path: '.gitignore',
        content: generateGitignore()
      })
    }
  }

  if (options.includeReadme) {
    files.push({
      path: 'README.md',
      content: generateReadme(buildState, options.format)
    })
  }

  return files
}

function generateAgentConfig(buildState: BuildState): any {
  const config: any = {
    model: buildState.brain?.config?.model || buildState.brain?.component.config?.model || 'claude-3-5-sonnet-20241022',
    temperature: buildState.brain?.config?.temperature ?? 0.7,
    max_tokens: buildState.brain?.config?.max_tokens || buildState.settings.token_budget || 1000,
    system_prompt: buildState.brain?.config?.system_prompt || '',
    streaming: buildState.brain?.config?.streaming ?? false,
    tools: buildState.tools.map(tool => ({
      name: tool.component.name,
      description: tool.component.metadata?.description || '',
      endpoint: tool.component.config?.endpoint || tool.component.interface?.endpoint || '',
      method: tool.component.config?.method || 'POST',
      auth: tool.component.config?.auth || 'none',
      parameters: tool.component.interface?.parameters || {}
    }))
  }

  return config
}

function generateTypeScriptCode(
  buildState: BuildState,
  buildId: string,
  timestamp: string,
  config: any
): string {
  const provider = buildState.brain?.component.provider || 'anthropic'
  const baseUrl = buildState.brain?.config?.base_url || buildState.brain?.component.config?.base_url
  
  // Use proxy API - no API keys required
  return generateProxyTypeScriptCode(buildId, timestamp, config, provider)
}

function generateProxyTypeScriptCode(buildId: string, timestamp: string, config: any, provider: string): string {
  return `// Generated by AgentEX
// Build ID: ${buildId}
// Generated: ${timestamp}
// Uses AgentEX proxy API - no API keys required

interface Message {
  role: "user" | "assistant";
  content: string;
}

interface AgentConfig {
  model: string;
  temperature: number;
  max_tokens: number;
  system_prompt?: string;
  streaming?: boolean;
  tools: any[];
}

const config: AgentConfig = ${JSON.stringify(config, null, 2)};

export async function runAgent(messages: Message[]) {
  try {
    const response = await fetch('/api/proxy/${provider}', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: config.model,
        messages: messages,
        temperature: config.temperature,
        max_tokens: config.max_tokens,
        ${config.system_prompt ? `system: config.system_prompt,` : ''}
        ${config.tools.length > 0 ? 'tools: config.tools,' : ''}
        ${config.streaming ? 'stream: true,' : ''}
      })
    });

    if (!response.ok) {
      throw new Error(\`API error: \${response.statusText}\`);
    }

    return await response.json();
  } catch (error) {
    console.error("Agent error:", error);
    throw error;
  }
}
`
}

function generateAnthropicTypeScriptCode(buildId: string, timestamp: string, config: any): string {
  return `// Generated by AgentEX
// Build ID: ${buildId}
// Generated: ${timestamp}

import Anthropic from "@anthropic-ai/sdk";

const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
});

interface Message {
  role: "user" | "assistant";
  content: string;
}

interface AgentConfig {
  model: string;
  temperature: number;
  max_tokens: number;
  system_prompt?: string;
  streaming?: boolean;
  tools: any[];
}

const config: AgentConfig = ${JSON.stringify(config, null, 2)};

export async function runAgent(messages: Message[]) {
  try {
    const response = await anthropic.messages.create({
      model: config.model,
      max_tokens: config.max_tokens,
      temperature: config.temperature,
      messages: messages,
      ${config.tools.length > 0 ? 'tools: config.tools,' : ''}
      ${config.system_prompt ? `system: config.system_prompt,` : ''}
    });

    return response;
  } catch (error) {
    console.error("Agent error:", error);
    throw error;
  }
}
`
}

function generateOpenClawTypeScriptCode(buildId: string, timestamp: string, config: any, baseUrl?: string): string {
  const apiUrl = baseUrl || 'https://api.openclaw.ai/v1'
  return `// Generated by AgentEX
// Build ID: ${buildId}
// Generated: ${timestamp}

interface Message {
  role: "user" | "assistant";
  content: string;
}

interface AgentConfig {
  model: string;
  temperature: number;
  max_tokens: number;
  system_prompt?: string;
  streaming?: boolean;
  tools: any[];
  base_url?: string;
}

const config: AgentConfig = ${JSON.stringify({ ...config, base_url: apiUrl }, null, 2)};

export async function runAgent(messages: Message[]) {
  try {
    const response = await fetch(\`\${config.base_url || '${apiUrl}'}/chat/completions\`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': \`Bearer \${process.env.OPENCLAW_API_KEY}\`
      },
      body: JSON.stringify({
        model: config.model,
        messages: messages,
        temperature: config.temperature,
        max_tokens: config.max_tokens,
        ${config.system_prompt ? `system: config.system_prompt,` : ''}
        ${config.tools.length > 0 ? 'tools: config.tools,' : ''}
        ${config.streaming ? 'stream: true,' : ''}
      })
    });

    if (!response.ok) {
      throw new Error(\`OpenClaw API error: \${response.statusText}\`);
    }

    return await response.json();
  } catch (error) {
    console.error("Agent error:", error);
    throw error;
  }
}
`
}

function generateOpenAITypeScriptCode(buildId: string, timestamp: string, config: any): string {
  return `// Generated by AgentEX
// Build ID: ${buildId}
// Generated: ${timestamp}

import OpenAI from "openai";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

interface Message {
  role: "user" | "assistant";
  content: string;
}

interface AgentConfig {
  model: string;
  temperature: number;
  max_tokens: number;
  system_prompt?: string;
  streaming?: boolean;
  tools: any[];
}

const config: AgentConfig = ${JSON.stringify(config, null, 2)};

export async function runAgent(messages: Message[]) {
  try {
    const response = await openai.chat.completions.create({
      model: config.model,
      messages: messages,
      temperature: config.temperature,
      max_tokens: config.max_tokens,
      ${config.tools.length > 0 ? 'tools: config.tools,' : ''}
    });

    return response;
  } catch (error) {
    console.error("Agent error:", error);
    throw error;
  }
}
`
}

function generateNextJSRoute(): string {
  return `import { NextRequest, NextResponse } from 'next/server';
import { runAgent } from '@/agent';

export async function POST(request: NextRequest) {
  try {
    const { messages } = await request.json();
    const response = await runAgent(messages);
    return NextResponse.json(response);
  } catch (error: any) {
    return NextResponse.json(
      { error: error.message },
      { status: 500 }
    );
  }
}
`
}

function generatePythonCode(
  buildState: BuildState,
  buildId: string,
  timestamp: string,
  config: any
): string {
  const provider = buildState.brain?.component.provider || 'anthropic'
  const baseUrl = buildState.brain?.config?.base_url || buildState.brain?.component.config?.base_url
  
  // Generate provider-specific code
  if (provider === 'openclaw') {
    return generateOpenClawPythonCode(buildId, timestamp, config, baseUrl)
  } else if (provider === 'openai') {
    return generateOpenAIPythonCode(buildId, timestamp, config)
  } else {
    // Default to Anthropic
    return generateAnthropicPythonCode(buildId, timestamp, config)
  }
}

function generateAnthropicPythonCode(buildId: string, timestamp: string, config: any): string {
  return `# Generated by AgentEX
# Build ID: ${buildId}
# Generated: ${timestamp}

import os
from anthropic import Anthropic
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Optional

app = FastAPI()
client = Anthropic(api_key=os.environ.get("ANTHROPIC_API_KEY"))

class Message(BaseModel):
    role: str
    content: str

class AgentRequest(BaseModel):
    messages: List[Message]

# Agent configuration
AGENT_CONFIG = ${JSON.stringify(config, null, 2).replace(/"/g, "'")}

@app.post("/agent")
async def run_agent(request: AgentRequest):
    try:
        response = client.messages.create(
            model=AGENT_CONFIG["model"],
            max_tokens=AGENT_CONFIG["max_tokens"],
            temperature=AGENT_CONFIG["temperature"],
            messages=[msg.dict() for msg in request.messages],
            ${config.tools.length > 0 ? 'tools=AGENT_CONFIG.get("tools", []),' : ''}
            ${config.system_prompt ? `system=AGENT_CONFIG.get("system_prompt"),` : ''}
        )
        return response
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
`
}

function generateOpenClawPythonCode(buildId: string, timestamp: string, config: any, baseUrl?: string): string {
  const apiUrl = baseUrl || 'https://api.openclaw.ai/v1'
  return `# Generated by AgentEX
# Build ID: ${buildId}
# Generated: ${timestamp}

import os
import httpx
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Optional

app = FastAPI()

class Message(BaseModel):
    role: str
    content: str

class AgentRequest(BaseModel):
    messages: List[Message]

# Agent configuration
AGENT_CONFIG = ${JSON.stringify({ ...config, base_url: apiUrl }, null, 2).replace(/"/g, "'")}

@app.post("/agent")
async def run_agent(request: AgentRequest):
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{AGENT_CONFIG.get('base_url', '${apiUrl}')}/chat/completions",
                headers={
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {os.environ.get('OPENCLAW_API_KEY')}"
                },
                json={
                    "model": AGENT_CONFIG["model"],
                    "messages": [msg.dict() for msg in request.messages],
                    "temperature": AGENT_CONFIG["temperature"],
                    "max_tokens": AGENT_CONFIG["max_tokens"],
                    ${config.system_prompt ? '"system": AGENT_CONFIG.get("system_prompt"),' : ''}
                    ${config.tools.length > 0 ? '"tools": AGENT_CONFIG.get("tools", []),' : ''}
                    ${config.streaming ? '"stream": True,' : ''}
                }
            )
            response.raise_for_status()
            return response.json()
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
`
}

function generateOpenAIPythonCode(buildId: string, timestamp: string, config: any): string {
  return `# Generated by AgentEX
# Build ID: ${buildId}
# Generated: ${timestamp}

import os
from openai import OpenAI
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List

app = FastAPI()
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

class Message(BaseModel):
    role: str
    content: str

class AgentRequest(BaseModel):
    messages: List[Message]

# Agent configuration
AGENT_CONFIG = ${JSON.stringify(config, null, 2).replace(/"/g, "'")}

@app.post("/agent")
async def run_agent(request: AgentRequest):
    try:
        response = client.chat.completions.create(
            model=AGENT_CONFIG["model"],
            messages=[msg.dict() for msg in request.messages],
            temperature=AGENT_CONFIG["temperature"],
            max_tokens=AGENT_CONFIG["max_tokens"],
            ${config.tools.length > 0 ? 'tools=AGENT_CONFIG.get("tools", []),' : ''}
        )
        return response
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
`
}

function generatePackageJson(buildState: BuildState): string {
  const provider = buildState.brain?.component.provider || 'anthropic'
  
  const dependencies: any = {
    'next': '^14.0.0',
    'react': '^18.0.0',
    'react-dom': '^18.0.0'
  }
  
  // Add provider-specific dependencies
  if (provider === 'openclaw') {
    // OpenClaw uses fetch API, no additional SDK needed
  } else if (provider === 'openai') {
    dependencies['openai'] = '^4.0.0'
  } else {
    // Default to Anthropic
    dependencies['@anthropic-ai/sdk'] = '^0.24.0'
  }
  
  return JSON.stringify({
    name: buildState.settings.name.toLowerCase().replace(/\s+/g, '-'),
    version: '0.1.0',
    description: buildState.settings.description || 'AgentEX generated agent',
    scripts: {
      dev: 'next dev',
      build: 'next build',
      start: 'next start'
    },
    dependencies,
    devDependencies: {
      '@types/node': '^20.0.0',
      '@types/react': '^18.0.0',
      '@types/react-dom': '^18.0.0',
      'typescript': '^5.0.0'
    }
  }, null, 2)
}

function generateRequirementsTxt(buildState: BuildState): string {
  // No provider-specific dependencies needed - using proxy API
  return `fastapi>=0.104.0
uvicorn>=0.24.0
pydantic>=2.0.0
httpx>=0.25.0
`
  
  return requirements
}

function generateEnvExample(buildState: BuildState): string {
  // No API keys needed - using proxy
  return `# No API keys required - AgentEX proxy handles authentication
# If deploying to a different domain, update the proxy URL in agent code
`
}

function generateGitignore(): string {
  return `node_modules
.next
.env
*.log
.DS_Store
`
}

function generateReadme(buildState: BuildState, format: 'typescript' | 'python'): string {
  const brainName = buildState.brain?.component.name || 'Unknown'
  const toolsCount = buildState.tools.length
  const runtimeName = buildState.runtime?.component.name || 'Unknown'

  return `# ${buildState.settings.name}

${buildState.settings.description || 'Generated by AgentEX'}

## Build Configuration

- **Brain**: ${brainName}
- **Tools**: ${toolsCount} tool(s)
- **Runtime**: ${runtimeName}
- **Token Budget**: ${buildState.settings.token_budget}

## Setup

${format === 'typescript' ? `
1. Install dependencies:
\`\`\`bash
npm install
\`\`\`

2. Set up environment variables:
\`\`\`bash
cp .env.example .env
# Edit .env and add your ANTHROPIC_API_KEY
\`\`\`

3. Run development server:
\`\`\`bash
npm run dev
\`\`\`

4. Deploy to Vercel:
\`\`\`bash
vercel
\`\`\`
` : `
1. Install dependencies:
\`\`\`bash
pip install -r requirements.txt
\`\`\`

2. Set up environment variables:
\`\`\`bash
export ANTHROPIC_API_KEY=your_api_key_here
\`\`\`

3. Run the server:
\`\`\`bash
python agent.py
\`\`\`

4. The API will be available at http://localhost:8000
\`\`\`
`}

## Usage

${format === 'typescript' ? `
Send POST requests to \`/api/agent\` with messages:

\`\`\`json
{
  "messages": [
    { "role": "user", "content": "Hello!" }
  ]
}
\`\`\`
` : `
Send POST requests to \`/agent\` with messages:

\`\`\`json
{
  "messages": [
    { "role": "user", "content": "Hello!" }
  ]
}
\`\`\`
`}

## Author

${buildState.settings.author || 'Generated by AgentEX'}

---
Generated by [AgentEX](https://github.com/agentex) on ${new Date().toISOString()}
`
}
